<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Machine Learning,">










<meta name="description" content="@LoyFan  &amp;gt;吴恩达机器学习课程链接&amp;gt;课程总结和笔记链接实验三的原始代码和使用数据可至课程链接-课时67-章节9编程作业中下载 包括了实验二中的使用了正则化项后的逻辑回归的最优化参数求解，重点是应用于多分类，采用一对多形式，对每一种分类进行“是/否”预测，得到分类。环境——Matlab R2018b/Octave  One-vs-allPart 1: Loading and Vi">
<meta name="keywords" content="Machine Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="吴恩达机器学习实验三完整代码">
<meta property="og:url" content="https://loyf.github.io/2019/04/16/吴恩达机器学习实验三完整代码/index.html">
<meta property="og:site_name" content="Loy With No Title">
<meta property="og:description" content="@LoyFan  &amp;gt;吴恩达机器学习课程链接&amp;gt;课程总结和笔记链接实验三的原始代码和使用数据可至课程链接-课时67-章节9编程作业中下载 包括了实验二中的使用了正则化项后的逻辑回归的最优化参数求解，重点是应用于多分类，采用一对多形式，对每一种分类进行“是/否”预测，得到分类。环境——Matlab R2018b/Octave  One-vs-allPart 1: Loading and Vi">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20190411211940132.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20190414143413118.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20190414143447894.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20190414143509662.png">
<meta property="og:updated_time" content="2019-04-20T02:00:55.942Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="吴恩达机器学习实验三完整代码">
<meta name="twitter:description" content="@LoyFan  &amp;gt;吴恩达机器学习课程链接&amp;gt;课程总结和笔记链接实验三的原始代码和使用数据可至课程链接-课时67-章节9编程作业中下载 包括了实验二中的使用了正则化项后的逻辑回归的最优化参数求解，重点是应用于多分类，采用一对多形式，对每一种分类进行“是/否”预测，得到分类。环境——Matlab R2018b/Octave  One-vs-allPart 1: Loading and Vi">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/20190411211940132.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://loyf.github.io/2019/04/16/吴恩达机器学习实验三完整代码/">





  <title>吴恩达机器学习实验三完整代码 | Loy With No Title</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Loy With No Title</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Life can not be planned</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://loyf.github.io/2019/04/16/吴恩达机器学习实验三完整代码/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Loy Fan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Loy With No Title">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">吴恩达机器学习实验三完整代码</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-16T20:54:04+08:00">
                2019-04-16
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>@<a href="https://loyf.github.io/">LoyFan</a></p>
<blockquote>
<p><a href="https://study.163.com/course/courseMain.htm?courseId=1004570029&amp;_trace_c_p_k2_=ea0c7bf2c97246f08030b6c79f38e69a" target="_blank" rel="noopener">&gt;吴恩达机器学习课程链接</a><br><a href="https://blog.csdn.net/weixin_43318626/article/details/88896788" target="_blank" rel="noopener">&gt;课程总结和笔记链接</a><br>实验三的原始代码和使用数据可至课程链接-课时67-章节9编程作业中下载</p>
<p>包括了实验二中的使用了正则化项后的逻辑回归的最优化参数求解，重点是应用于多分类，采用一对多形式，对每一种分类进行“是/否”预测，得到分类。<br>环境——Matlab R2018b/Octave</p>
</blockquote>
<h1 id="One-vs-all"><a href="#One-vs-all" class="headerlink" title="One-vs-all"></a>One-vs-all</h1><h2 id="Part-1-Loading-and-Visualizing-Data"><a href="#Part-1-Loading-and-Visualizing-Data" class="headerlink" title="Part 1: Loading and Visualizing Data"></a>Part 1: Loading and Visualizing Data</h2><p>这个训练集一共有5000条数据，每条数据包含400维特征。一共10个分类。<br><strong>运行结果</strong></p>
<p><img src="https://img-blog.csdnimg.cn/20190411211940132.png" width="40%" alt></p>
<a id="more"></a>
<h2 id="Part-2a-Vectorize-Logistic-Regression"><a href="#Part-2a-Vectorize-Logistic-Regression" class="headerlink" title="Part 2a: Vectorize Logistic Regression"></a>Part 2a: Vectorize Logistic Regression</h2><p><strong>lrCostFunction.m</strong><br>加入正则化项的逻辑回归的损失函数计算，和实验二中的相同。<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">function [J, grad] = lrCostFunction(theta, X, y, lambda)</span><br><span class="line">%LRCOSTFUNCTION Compute cost and gradient <span class="keyword">for</span> logistic regression <span class="keyword">with</span> </span><br><span class="line">%regularization</span><br><span class="line">%   J = LRCOSTFUNCTION(theta, X, y, lambda) computes the cost <span class="keyword">of</span> using</span><br><span class="line">%   theta <span class="keyword">as</span> the parameter <span class="keyword">for</span> regularized logistic regression and the</span><br><span class="line">%   gradient <span class="keyword">of</span> the cost w.r.t. to the parameters. </span><br><span class="line"></span><br><span class="line">% Initialize some useful values</span><br><span class="line">m = length(y); % number <span class="keyword">of</span> training examples</span><br><span class="line"></span><br><span class="line">% You need to <span class="keyword">return</span> the following variables correctly </span><br><span class="line">J = <span class="number">0</span>;</span><br><span class="line">grad = zeros(size(theta));</span><br><span class="line"></span><br><span class="line">% ====================== YOUR CODE HERE ======================</span><br><span class="line">% Instructions: Compute the cost <span class="keyword">of</span> a particular choice <span class="keyword">of</span> theta.</span><br><span class="line">%               You should <span class="keyword">set</span> J to the cost.</span><br><span class="line">%               Compute the partial derivatives and <span class="keyword">set</span> grad to the partial</span><br><span class="line">%               derivatives of the cost w.r.t. each parameter in theta</span><br><span class="line">%</span><br><span class="line">% Hint: The computation of the cost function and gradients can be</span><br><span class="line">%       efficiently vectorized. For example, consider the computation</span><br><span class="line">%</span><br><span class="line">%           sigmoid(X * theta)</span><br><span class="line">%</span><br><span class="line">%       Each row of the resulting matrix will contain the value of the</span><br><span class="line">%       prediction for that example. You can make use of this to vectorize</span><br><span class="line">%       the cost function and gradient computations. </span><br><span class="line">%</span><br><span class="line">% Hint: When computing the gradient of the regularized cost function, </span><br><span class="line">%       there're many possible vectorized solutions, but one solution</span><br><span class="line">%       looks like:</span><br><span class="line">%           grad = (unregularized gradient for logistic regression)</span><br><span class="line">%           temp = theta; </span><br><span class="line">%           temp(1) = 0;   % because we don't add anything for j = 0  </span><br><span class="line">%           grad = grad + YOUR_CODE_HERE (using the temp variable)</span><br><span class="line">%</span><br><span class="line"></span><br><span class="line">pos = y == 1;</span><br><span class="line">neg = y == 0;</span><br><span class="line"></span><br><span class="line">h_pos = sigmoid(X(pos, :) * theta);</span><br><span class="line">J_pos = sum(-log(h_pos));</span><br><span class="line"></span><br><span class="line">h_neg = sigmoid(X(neg, :) * theta);</span><br><span class="line">J_neg = sum(-log(1 - h_neg));</span><br><span class="line"></span><br><span class="line">J_reg = lambda/2 * sum(theta(2:end, :) .^ 2);</span><br><span class="line">J = (J_pos + J_neg + J_reg)/m;</span><br><span class="line"></span><br><span class="line">grad = (sum(X .* (sigmoid(X * theta) - y)))' / m;</span><br><span class="line">grad_reg = ((lambda * theta(2:end, :)) / m);</span><br><span class="line">grad(2:end, :) = grad(2:end, :) + grad_reg;</span><br><span class="line"></span><br><span class="line">% =============================================================</span><br><span class="line"></span><br><span class="line">grad = grad(:);</span><br><span class="line"></span><br><span class="line">end</span><br></pre></td></tr></table></figure></p>
<p><strong>运行结果</strong></p>
<pre><code>Testing lrCostFunction() with regularization
Cost: 2.534819
Expected cost: 2.534819
Gradients:
 0.146561 
 -0.548558 
 0.724722 
 1.398003 
Expected gradients:
 0.146561
 -0.548558
 0.724722
 1.398003
Program paused. Press enter to continue.
</code></pre><h2 id="Part-2b-One-vs-All-Training"><a href="#Part-2b-One-vs-All-Training" class="headerlink" title="Part 2b: One-vs-All Training"></a>Part 2b: One-vs-All Training</h2><p><strong>oneVsAll.m</strong><br>通过最小化损失函数计算所有十个类别的最优参数。<br>参数为10行400列矩阵。<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"> function [all_theta] = oneVsAll(X, y, num_labels, lambda)</span><br><span class="line">%ONEVSALL trains multiple logistic regression classifiers and returns all</span><br><span class="line">%the classifiers <span class="keyword">in</span> a matrix all_theta, where the i-th row <span class="keyword">of</span> all_theta </span><br><span class="line">%corresponds to the classifier <span class="keyword">for</span> label i</span><br><span class="line">%   [all_theta] = ONEVSALL(X, y, num_labels, lambda) trains num_labels</span><br><span class="line">%   logistic regression classifiers and returns each <span class="keyword">of</span> these classifiers</span><br><span class="line">%   <span class="keyword">in</span> a matrix all_theta, where the i-th row <span class="keyword">of</span> all_theta corresponds </span><br><span class="line">%   to the classifier <span class="keyword">for</span> label i</span><br><span class="line"></span><br><span class="line">% Some useful variables</span><br><span class="line">m = size(X, <span class="number">1</span>);%<span class="number">5000</span></span><br><span class="line">n = size(X, <span class="number">2</span>);%<span class="number">400</span></span><br><span class="line"></span><br><span class="line">% You need to <span class="keyword">return</span> the following variables correctly </span><br><span class="line">all_theta = zeros(num_labels, n + <span class="number">1</span>);%<span class="number">10</span>*<span class="number">401</span></span><br><span class="line"></span><br><span class="line">% Add ones to the X data matrix</span><br><span class="line">X = [ones(m, <span class="number">1</span>) X];</span><br><span class="line"></span><br><span class="line">% ====================== YOUR CODE HERE ======================</span><br><span class="line">% Instructions: You should complete the following code to train num_labels</span><br><span class="line">%               logistic regression classifiers <span class="keyword">with</span> regularization</span><br><span class="line">%               parameter lambda. </span><br><span class="line">%</span><br><span class="line">% Hint: theta(:) will <span class="keyword">return</span> a column vector.</span><br><span class="line">%</span><br><span class="line">% Hint: You can use y == c to obtain a vector <span class="keyword">of</span> <span class="number">1</span><span class="string">'s and 0'</span>s that tell you</span><br><span class="line">%       whether the ground truth is <span class="literal">true</span>/<span class="literal">false</span> <span class="keyword">for</span> <span class="keyword">this</span> <span class="class"><span class="keyword">class</span>.</span></span><br><span class="line"><span class="class">%</span></span><br><span class="line">% Note: For this assignment, we recommend using fmincg to optimize the cost</span><br><span class="line">%       <span class="function"><span class="keyword">function</span>. <span class="title">It</span> <span class="title">is</span> <span class="title">okay</span> <span class="title">to</span> <span class="title">use</span> <span class="title">a</span> <span class="title">for</span>-<span class="title">loop</span> (<span class="params">for c = <span class="number">1</span>:num_labels</span>) <span class="title">to</span></span></span><br><span class="line">%       loop over the different classes.</span><br><span class="line">%</span><br><span class="line">%       fmincg works similarly to fminunc, but is more efficient when we</span><br><span class="line">%       are dealing <span class="keyword">with</span> large number <span class="keyword">of</span> parameters.</span><br><span class="line">%</span><br><span class="line">% Example Code <span class="keyword">for</span> fmincg:</span><br><span class="line">%</span><br><span class="line">%     % <span class="built_in">Set</span> Initial theta</span><br><span class="line">%     initial_theta = zeros(n + <span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line">%     </span><br><span class="line">%     % <span class="built_in">Set</span> options <span class="keyword">for</span> fminunc</span><br><span class="line">%     options = optimset(<span class="string">'GradObj'</span>, <span class="string">'on'</span>, <span class="string">'MaxIter'</span>, <span class="number">50</span>);</span><br><span class="line">% </span><br><span class="line">%     % Run fmincg to obtain the optimal theta</span><br><span class="line">%     % This <span class="function"><span class="keyword">function</span> <span class="title">will</span> <span class="title">return</span> <span class="title">theta</span> <span class="title">and</span> <span class="title">the</span> <span class="title">cost</span> </span></span><br><span class="line">%     [theta] = ...</span><br><span class="line">%         fmincg (@(t)(lrCostFunction(t, X, (y == c), lambda)), ...</span><br><span class="line">%                 initial_theta, options);</span><br><span class="line">%</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> c = <span class="number">1</span>:num_labels</span><br><span class="line"></span><br><span class="line">    % Initialize fitting parameters</span><br><span class="line">    initial_theta = zeros(n + <span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    % <span class="built_in">Set</span> Options</span><br><span class="line">    options = optimset(<span class="string">'GradObj'</span>, <span class="string">'on'</span>, <span class="string">'MaxIter'</span>, <span class="number">50</span>);</span><br><span class="line"></span><br><span class="line">    % Optimize</span><br><span class="line">    [all_theta(c, :), J, exit_flag] = ...</span><br><span class="line">        fmincg (@(t)(lrCostFunction(t, X, (y == c), lambda)), initial_theta, options);</span><br><span class="line"></span><br><span class="line">% =========================================================================</span><br><span class="line"></span><br><span class="line">end</span><br></pre></td></tr></table></figure></p>
<h2 id="Part-3-Predict-for-One-Vs-All"><a href="#Part-3-Predict-for-One-Vs-All" class="headerlink" title="Part 3: Predict for One-Vs-All"></a>Part 3: Predict for One-Vs-All</h2><p><strong>predictOneVsAll.m</strong><br>使用得到的10<em>400参数对数据进行预测（用训练集预测哈哈哈）<br>首先得到all_p为5000</em>10的矩阵，包含0、1，得到5000个数据的预测分类<br>找到每一行的1值序号，得到p为5000*1的向量，是每一个数据的预测分类。<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">p</span> = <span class="title">predictOneVsAll</span>(<span class="params">all_theta, X</span>)</span></span><br><span class="line">%PREDICT Predict the label for a trained one-vs-all classifier. The labels </span><br><span class="line">%are <span class="keyword">in</span> the range <span class="number">1.</span>.K, where K = size(all_theta, <span class="number">1</span>). </span><br><span class="line">%  p = PREDICTONEVSALL(all_theta, X) will <span class="keyword">return</span> a vector <span class="keyword">of</span> predictions</span><br><span class="line">%  <span class="keyword">for</span> each example <span class="keyword">in</span> the matrix X. Note that X contains the examples <span class="keyword">in</span></span><br><span class="line">%  rows. all_theta is a matrix where the i-th row is a trained logistic</span><br><span class="line">%  regression theta vector <span class="keyword">for</span> the i-th <span class="class"><span class="keyword">class</span>. <span class="title">You</span> <span class="title">should</span> <span class="title">set</span> <span class="title">p</span> <span class="title">to</span> <span class="title">a</span> <span class="title">vector</span></span></span><br><span class="line"><span class="class">%  <span class="title">of</span> <span class="title">values</span> <span class="title">from</span> 1..<span class="title">K</span> (<span class="title">e</span>.<span class="title">g</span>., <span class="title">p</span> </span>= [<span class="number">1</span>; <span class="number">3</span>; <span class="number">1</span>; <span class="number">2</span>] predicts classes <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span></span><br><span class="line">%  <span class="keyword">for</span> <span class="number">4</span> examples) </span><br><span class="line"></span><br><span class="line">m = size(X, <span class="number">1</span>);%<span class="number">5000</span></span><br><span class="line">num_labels = size(all_theta, <span class="number">1</span>);%<span class="number">10</span></span><br><span class="line"></span><br><span class="line">% You need to <span class="keyword">return</span> the following variables correctly </span><br><span class="line">p = zeros(size(X, <span class="number">1</span>), <span class="number">1</span>);%<span class="number">5000</span>*<span class="number">1</span></span><br><span class="line"></span><br><span class="line">% Add ones to the X data matrix</span><br><span class="line">X = [ones(m, <span class="number">1</span>) X];</span><br><span class="line"></span><br><span class="line">% ====================== YOUR CODE HERE ======================</span><br><span class="line">% Instructions: Complete the following code to make predictions using</span><br><span class="line">%               your learned logistic regression parameters (one-vs-all).</span><br><span class="line">%               You should <span class="keyword">set</span> p to a vector of predictions (from 1 to</span><br><span class="line">%               num_labels).</span><br><span class="line">%</span><br><span class="line">% Hint: This code can be done all vectorized using the max function.</span><br><span class="line">%       In particular, the max function can also return the index of the </span><br><span class="line">%       max element, for more information see 'help max'. If your examples </span><br><span class="line">%       are in rows, then, you can use max(A, [], 2) to obtain the max </span><br><span class="line">%       for each row.</span><br><span class="line">%       </span><br><span class="line"></span><br><span class="line">all_p = floor(sigmoid(X * (all_theta)') / 0.5);</span><br><span class="line">[val, p] = max(all_p, [], 2);</span><br><span class="line"></span><br><span class="line">% =========================================================================</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">end</span><br></pre></td></tr></table></figure></p>
<p><strong>运行结果</strong><br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Training <span class="built_in">Set</span> Accuracy: <span class="number">89.160000</span></span><br></pre></td></tr></table></figure></p>
<h2 id="主函数"><a href="#主函数" class="headerlink" title="主函数"></a>主函数</h2><p><strong>ex3.m</strong><br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line">%% Machine Learning Online Class - Exercise <span class="number">3</span> | Part <span class="number">1</span>: One-vs-all</span><br><span class="line"></span><br><span class="line">%  Instructions</span><br><span class="line">%  ------------</span><br><span class="line">%</span><br><span class="line">%  This file contains code that helps you <span class="keyword">get</span> started on the</span><br><span class="line">%  linear exercise. You will need to complete the following functions</span><br><span class="line">%  in this exericse:</span><br><span class="line">%</span><br><span class="line">%     lrCostFunction.m (logistic regression cost function)</span><br><span class="line">%     oneVsAll.m</span><br><span class="line">%     predictOneVsAll.m</span><br><span class="line">%     predict.m</span><br><span class="line">%</span><br><span class="line">%  For this exercise, you will not need to change any code in this file,</span><br><span class="line">%  or any other files other than those mentioned above.</span><br><span class="line">%</span><br><span class="line"></span><br><span class="line">%% Initialization</span><br><span class="line">clear ; close all; clc</span><br><span class="line"></span><br><span class="line">%% Setup the parameters you will use for this part of the exercise</span><br><span class="line">input_layer_size  = 400;  % 20x20 Input Images of Digits</span><br><span class="line">num_labels = 10;          % 10 labels, from 1 to 10</span><br><span class="line">                          % (note that we have mapped "0" to label 10)</span><br><span class="line"></span><br><span class="line">%% =========== Part 1: Loading and Visualizing Data =============</span><br><span class="line">%  We start the exercise by first loading and visualizing the dataset.</span><br><span class="line">%  You will be working with a dataset that contains handwritten digits.</span><br><span class="line">%</span><br><span class="line"></span><br><span class="line">% Load Training Data</span><br><span class="line">fprintf('Loading and Visualizing Data ...\n')</span><br><span class="line"></span><br><span class="line">load('ex3data1.mat'); % training data stored in arrays X, y</span><br><span class="line">m = size(X, 1);</span><br><span class="line"></span><br><span class="line">% Randomly select 100 data points to display</span><br><span class="line">rand_indices = randperm(m);</span><br><span class="line">sel = X(rand_indices(1:100), :);</span><br><span class="line"></span><br><span class="line">displayData(sel);</span><br><span class="line"></span><br><span class="line">fprintf('Program paused. Press enter to continue.\n');</span><br><span class="line">pause;</span><br><span class="line"></span><br><span class="line">%% ============ Part 2a: Vectorize Logistic Regression ============</span><br><span class="line">%  In this part of the exercise, you will reuse your logistic regression</span><br><span class="line">%  code from the last exercise. You task here is to make sure that your</span><br><span class="line">%  regularized logistic regression implementation is vectorized. After</span><br><span class="line">%  that, you will implement one-vs-all classification for the handwritten</span><br><span class="line">%  digit dataset.</span><br><span class="line">%</span><br><span class="line"></span><br><span class="line">% Test case for lrCostFunction</span><br><span class="line">fprintf('\nTesting lrCostFunction() with regularization');</span><br><span class="line"></span><br><span class="line">theta_t = [-2; -1; 1; 2];</span><br><span class="line">X_t = [ones(5,1) reshape(1:15,5,3)/10];</span><br><span class="line">y_t = ([1;0;1;0;1] &gt;= 0.5);</span><br><span class="line">lambda_t = 3;</span><br><span class="line">[J grad] = lrCostFunction(theta_t, X_t, y_t, lambda_t);</span><br><span class="line"></span><br><span class="line">fprintf('\nCost: %f\n', J);</span><br><span class="line">fprintf('Expected cost: 2.534819\n');</span><br><span class="line">fprintf('Gradients:\n');</span><br><span class="line">fprintf(' %f \n', grad);</span><br><span class="line">fprintf('Expected gradients:\n');</span><br><span class="line">fprintf(' 0.146561\n -0.548558\n 0.724722\n 1.398003\n');</span><br><span class="line"></span><br><span class="line">fprintf('Program paused. Press enter to continue.\n');</span><br><span class="line">pause;</span><br><span class="line">%% ============ Part 2b: One-vs-All Training ============</span><br><span class="line">fprintf('\nTraining One-vs-All Logistic Regression...\n')</span><br><span class="line"></span><br><span class="line">lambda = 0.1;</span><br><span class="line">[all_theta] = oneVsAll(X, y, num_labels, lambda);</span><br><span class="line"></span><br><span class="line">fprintf('Program paused. Press enter to continue.\n');</span><br><span class="line">pause;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">%% ================ Part 3: Predict for One-Vs-All ================</span><br><span class="line"></span><br><span class="line">pred = predictOneVsAll(all_theta, X);</span><br><span class="line"></span><br><span class="line">fprintf('\nTraining Set Accuracy: %f\n', mean(double(pred == y)) * 100);</span><br></pre></td></tr></table></figure></p>
<h1 id="Neural-Networks"><a href="#Neural-Networks" class="headerlink" title="Neural Networks"></a>Neural Networks</h1><h2 id="Part-1-Loading-and-Visualizing-Data-1"><a href="#Part-1-Loading-and-Visualizing-Data-1" class="headerlink" title="Part 1: Loading and Visualizing Data"></a>Part 1: Loading and Visualizing Data</h2><p><img src="https://img-blog.csdnimg.cn/20190414143413118.png" width="40%" alt></p>
<h2 id="Part-2-Loading-Pameters"><a href="#Part-2-Loading-Pameters" class="headerlink" title="Part 2: Loading Pameters"></a>Part 2: Loading Pameters</h2><h2 id="Part-3-Implement-Predict"><a href="#Part-3-Implement-Predict" class="headerlink" title="Part 3: Implement Predict"></a>Part 3: Implement Predict</h2><p><strong>predict.m</strong><br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">p</span> = <span class="title">predict</span>(<span class="params">Theta1, Theta2, X</span>)</span></span><br><span class="line">%PREDICT Predict the label of an input given a trained neural network</span><br><span class="line">%   p = PREDICT(Theta1, Theta2, X) outputs the predicted label <span class="keyword">of</span> X given the</span><br><span class="line">%   trained weights <span class="keyword">of</span> a neural network (Theta1, Theta2)</span><br><span class="line"></span><br><span class="line">% Useful values</span><br><span class="line">m = size(X, <span class="number">1</span>);</span><br><span class="line">num_labels = size(Theta2, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">% You need to <span class="keyword">return</span> the following variables correctly </span><br><span class="line">p = zeros(size(X, <span class="number">1</span>), <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">% ====================== YOUR CODE HERE ======================</span><br><span class="line">% Instructions: Complete the following code to make predictions using</span><br><span class="line">%               your learned neural network. You should <span class="keyword">set</span> p to a </span><br><span class="line">%               vector containing labels between 1 to num_labels.</span><br><span class="line">%</span><br><span class="line">% Hint: The max function might come in useful. In particular, the max</span><br><span class="line">%       function can also return the index of the max element, for more</span><br><span class="line">%       information see 'help max'. If your examples are in rows, then, you</span><br><span class="line">%       can use max(A, [], 2) to obtain the max for each row.</span><br><span class="line">%</span><br><span class="line">X = [ones(m, 1) X];</span><br><span class="line">all_p = floor(sigmoid(X * (Theta1)') / 0.5);</span><br><span class="line">all_p = [ones(m, 1) all_p];</span><br><span class="line">all_p = floor(sigmoid(all_p * (Theta2)') / 0.5);</span><br><span class="line">[val, p] = max(all_p, [], 2);</span><br><span class="line"></span><br><span class="line">% =========================================================================</span><br><span class="line"></span><br><span class="line">end</span><br></pre></td></tr></table></figure></p>
<p><strong>实验结果</strong></p>
<pre><code>Loading and Visualizing Data ...
Program paused. Press enter to continue.

Loading Saved Neural Network Parameters ...

Training Set Accuracy: 95.400000
Program paused. Press enter to continue.

Displaying Example Image

Neural Network Prediction: 8 (digit 8)
Paused - press enter to continue, q to exit:

Displaying Example Image

Neural Network Prediction: 2 (digit 2)
Paused - press enter to continue, q to exit:
</code></pre><p><img src="https://img-blog.csdnimg.cn/20190414143447894.png" width="40%" alt><br><img src="https://img-blog.csdnimg.cn/20190414143509662.png" width="40%" alt></p>
<h2 id="主函数-1"><a href="#主函数-1" class="headerlink" title="主函数"></a>主函数</h2><p><strong>ex3_nn.m</strong><br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line">%% Machine Learning Online Class - Exercise <span class="number">3</span> | Part <span class="number">2</span>: Neural Networks</span><br><span class="line"></span><br><span class="line">%  Instructions</span><br><span class="line">%  ------------</span><br><span class="line">% </span><br><span class="line">%  This file contains code that helps you <span class="keyword">get</span> started on the</span><br><span class="line">%  linear exercise. You will need to complete the following functions </span><br><span class="line">%  in this exericse:</span><br><span class="line">%</span><br><span class="line">%     lrCostFunction.m (logistic regression cost function)</span><br><span class="line">%     oneVsAll.m</span><br><span class="line">%     predictOneVsAll.m</span><br><span class="line">%     predict.m</span><br><span class="line">%</span><br><span class="line">%  For this exercise, you will not need to change any code in this file,</span><br><span class="line">%  or any other files other than those mentioned above.</span><br><span class="line">%</span><br><span class="line"></span><br><span class="line">%% Initialization</span><br><span class="line">clear ; close all; clc</span><br><span class="line"></span><br><span class="line">%% Setup the parameters you will use for this exercise</span><br><span class="line">input_layer_size  = 400;  % 20x20 Input Images of Digits</span><br><span class="line">hidden_layer_size = 25;   % 25 hidden units</span><br><span class="line">num_labels = 10;          % 10 labels, from 1 to 10   </span><br><span class="line">                          % (note that we have mapped "0" to label 10)</span><br><span class="line"></span><br><span class="line">%% =========== Part 1: Loading and Visualizing Data =============</span><br><span class="line">%  We start the exercise by first loading and visualizing the dataset. </span><br><span class="line">%  You will be working with a dataset that contains handwritten digits.</span><br><span class="line">%</span><br><span class="line"></span><br><span class="line">% Load Training Data</span><br><span class="line">fprintf('Loading and Visualizing Data ...\n')</span><br><span class="line"></span><br><span class="line">load('ex3data1.mat');</span><br><span class="line">m = size(X, 1);%5000</span><br><span class="line"></span><br><span class="line">% Randomly select 100 data points to display</span><br><span class="line">sel = randperm(size(X, 1));</span><br><span class="line">sel = sel(1:100);</span><br><span class="line"></span><br><span class="line">displayData(X(sel, :));</span><br><span class="line"></span><br><span class="line">fprintf('Program paused. Press enter to continue.\n');</span><br><span class="line">pause;</span><br><span class="line"></span><br><span class="line">%% ================ Part 2: Loading Pameters ================</span><br><span class="line">% In this part of the exercise, we load some pre-initialized </span><br><span class="line">% neural network parameters.</span><br><span class="line"></span><br><span class="line">fprintf('\nLoading Saved Neural Network Parameters ...\n')</span><br><span class="line"></span><br><span class="line">% Load the weights into variables Theta1 and Theta2</span><br><span class="line">load('ex3weights.mat');%Theta1 25*401,Theta2 10*26</span><br><span class="line"></span><br><span class="line">%% ================= Part 3: Implement Predict =================</span><br><span class="line">%  After training the neural network, we would like to use it to predict</span><br><span class="line">%  the labels. You will now implement the "predict" function to use the</span><br><span class="line">%  neural network to predict the labels of the training <span class="keyword">set</span>. This lets</span><br><span class="line">%  you compute the training <span class="keyword">set</span> accuracy.</span><br><span class="line"></span><br><span class="line">pred = predict(Theta1, Theta2, X);</span><br><span class="line"></span><br><span class="line">fprintf('\nTraining Set Accuracy: %f\n', mean(double(pred == y)) * 100);</span><br><span class="line"></span><br><span class="line">fprintf('Program paused. Press enter to continue.\n');</span><br><span class="line">pause;</span><br><span class="line"></span><br><span class="line">%  To give you an idea of the network's output, you can also run</span><br><span class="line">%  through the examples one at the a time to see what it is predicting.</span><br><span class="line"></span><br><span class="line">%  Randomly permute examples</span><br><span class="line">rp = randperm(m);</span><br><span class="line"></span><br><span class="line">for i = 1:m</span><br><span class="line">    % Display </span><br><span class="line">    fprintf('\nDisplaying Example Image\n');</span><br><span class="line">    displayData(X(rp(i), :));</span><br><span class="line"></span><br><span class="line">    pred = predict(Theta1, Theta2, X(rp(i),:));</span><br><span class="line">    fprintf('\nNeural Network Prediction: %d (digit %d)\n', pred, mod(pred, 10));</span><br><span class="line">    </span><br><span class="line">    % Pause with quit option</span><br><span class="line">    s = input('Paused - press enter to continue, q to exit:','s');</span><br><span class="line">    if s == 'q'</span><br><span class="line">      break</span><br><span class="line">    end</span><br><span class="line">end</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>实验三完成</p>
</blockquote>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Machine-Learning/" rel="tag"><i class="fa fa-tag"></i> Machine Learning</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/04/16/吴恩达机器学习实验二完整代码/" rel="next" title="吴恩达机器学习实验二完整代码">
                <i class="fa fa-chevron-left"></i> 吴恩达机器学习实验二完整代码
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/04/23/反向传播算法-基于维基百科的理解-Back-Propagation-Wikipedia/" rel="prev" title="反向传播算法 基于维基百科的理解 | Back Propagation - Wikipedia">
                反向传播算法 基于维基百科的理解 | Back Propagation - Wikipedia <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Loy Fan</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#One-vs-all"><span class="nav-number">1.</span> <span class="nav-text">One-vs-all</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Part-1-Loading-and-Visualizing-Data"><span class="nav-number">1.1.</span> <span class="nav-text">Part 1: Loading and Visualizing Data</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Part-2a-Vectorize-Logistic-Regression"><span class="nav-number">1.2.</span> <span class="nav-text">Part 2a: Vectorize Logistic Regression</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Part-2b-One-vs-All-Training"><span class="nav-number">1.3.</span> <span class="nav-text">Part 2b: One-vs-All Training</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Part-3-Predict-for-One-Vs-All"><span class="nav-number">1.4.</span> <span class="nav-text">Part 3: Predict for One-Vs-All</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#主函数"><span class="nav-number">1.5.</span> <span class="nav-text">主函数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Neural-Networks"><span class="nav-number">2.</span> <span class="nav-text">Neural Networks</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Part-1-Loading-and-Visualizing-Data-1"><span class="nav-number">2.1.</span> <span class="nav-text">Part 1: Loading and Visualizing Data</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Part-2-Loading-Pameters"><span class="nav-number">2.2.</span> <span class="nav-text">Part 2: Loading Pameters</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Part-3-Implement-Predict"><span class="nav-number">2.3.</span> <span class="nav-text">Part 3: Implement Predict</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#主函数-1"><span class="nav-number">2.4.</span> <span class="nav-text">主函数</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Loy Fan</span>

  
</div>








<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">22.5k words in this blog site.</span>
</div>

        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
